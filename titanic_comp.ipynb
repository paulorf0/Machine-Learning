{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335722a4-0af6-4075-81dd-c235b0a58f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic Competition: https://www.kaggle.com/competitions/titanic/data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv('Dados/titanic/train.csv')\n",
    "test = pd.read_csv('Dados/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87bdade-a280-4b9f-a5ae-79401edfa6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 11), (418, 10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.set_index('PassengerId')\n",
    "test = test.set_index('PassengerId')\n",
    "\n",
    "train.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef716a0-225f-4b5b-9157-ef7b986c1325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Surname</th>\n",
       "      <th>size_family</th>\n",
       "      <th>travel_with_family</th>\n",
       "      <th>title_Master</th>\n",
       "      <th>title_Miss</th>\n",
       "      <th>title_Mr</th>\n",
       "      <th>title_Mrs</th>\n",
       "      <th>title_Rare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Braund</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Allen</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Montvila</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>Graham</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Johnston</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>Behr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Dooley</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "...               ...     ...   \n",
       "887                 0       2   \n",
       "888                 1       1   \n",
       "889                 0       3   \n",
       "890                 1       1   \n",
       "891                 0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "887                                      Montvila, Rev. Juozas    male  27.0   \n",
       "888                               Graham, Miss. Margaret Edith  female  19.0   \n",
       "889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "890                                      Behr, Mr. Karl Howell    male  26.0   \n",
       "891                                        Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "PassengerId                                                           \n",
       "1                1      0         A/5 21171   7.2500   NaN        S   \n",
       "2                1      0          PC 17599  71.2833   C85        C   \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "4                1      0            113803  53.1000  C123        S   \n",
       "5                0      0            373450   8.0500   NaN        S   \n",
       "...            ...    ...               ...      ...   ...      ...   \n",
       "887              0      0            211536  13.0000   NaN        S   \n",
       "888              0      0            112053  30.0000   B42        S   \n",
       "889              1      2        W./C. 6607  23.4500   NaN        S   \n",
       "890              0      0            111369  30.0000  C148        C   \n",
       "891              0      0            370376   7.7500   NaN        Q   \n",
       "\n",
       "               Surname  size_family  travel_with_family  title_Master  \\\n",
       "PassengerId                                                             \n",
       "1               Braund            2                   1           0.0   \n",
       "2              Cumings            1                   0           0.0   \n",
       "3            Heikkinen            1                   0           0.0   \n",
       "4             Futrelle            2                   1           0.0   \n",
       "5                Allen            2                   1           0.0   \n",
       "...                ...          ...                 ...           ...   \n",
       "887           Montvila            1                   0           0.0   \n",
       "888             Graham            3                   1           0.0   \n",
       "889           Johnston            2                   1           0.0   \n",
       "890               Behr            1                   0           0.0   \n",
       "891             Dooley            1                   0           0.0   \n",
       "\n",
       "             title_Miss  title_Mr  title_Mrs  title_Rare  \n",
       "PassengerId                                               \n",
       "1                   0.0       1.0        0.0         0.0  \n",
       "2                   0.0       0.0        1.0         0.0  \n",
       "3                   1.0       0.0        0.0         0.0  \n",
       "4                   0.0       0.0        1.0         0.0  \n",
       "5                   0.0       1.0        0.0         0.0  \n",
       "...                 ...       ...        ...         ...  \n",
       "887                 0.0       0.0        0.0         1.0  \n",
       "888                 1.0       0.0        0.0         0.0  \n",
       "889                 1.0       0.0        0.0         0.0  \n",
       "890                 0.0       1.0        0.0         0.0  \n",
       "891                 0.0       1.0        0.0         0.0  \n",
       "\n",
       "[891 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add new feature call 'travel_with_family', 'size_family' and title, based on last name\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "name_split_train = train['Name'].str.split(',').str\n",
    "title = name_split_train[1].str.split('.').str[0]\n",
    "train['Surname'] = name_split_train[0]\n",
    "train['title'] = title\n",
    "train['size_family'] = train['Surname'].map(train['Surname'].value_counts()).astype(int)\n",
    "train['travel_with_family'] = train['size_family'] > 1\n",
    "\n",
    "name_split_test = test['Name'].str.split(',').str\n",
    "title_test = name_split_test[1].str.split('.').str[0]\n",
    "test['Surname'] = name_split_test[0]\n",
    "test['title'] = title_test\n",
    "test['size_family'] = test['Surname'].map(test['Surname'].value_counts())\n",
    "test['travel_with_family'] = test['size_family'] > 1\n",
    "\n",
    "map_travel_with_family = {False: 0, True: 1}\n",
    "test['travel_with_family'] = test['travel_with_family'].map(map_travel_with_family)\n",
    "train['travel_with_family'] = train['travel_with_family'].map(map_travel_with_family)\n",
    "\n",
    "\n",
    "# Encoding Title\n",
    "# enc = OrdinalEncoder()\n",
    "# cabin_enc = enc.fit_transform(train[['title']])\n",
    "# train['title'] = cabin_enc[:, 0]\n",
    "\n",
    "# cabin_enc_test = enc.transform(test[['title']])\n",
    "# test['title'] = cabin_enc_test[:, 0]\n",
    "\n",
    "rare_titles = ['Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', \n",
    "                   'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Done']\n",
    "train['title'] = train['title'].str.strip()\n",
    "test['title'] = test['title'].str.strip()\n",
    "train['title'] = train['title'].replace(rare_titles, 'Rare')\n",
    "test['title'] = test['title'].replace(rare_titles, 'Rare')\n",
    "\n",
    "train['title'] = train['title'].replace('Mlle', 'Miss')\n",
    "train['title'] = train['title'].replace('Ms', 'Miss')\n",
    "train['title'] = train['title'].replace('Mme', 'Mrs')\n",
    "test['title'] = test['title'].replace('Mlle', 'Miss')\n",
    "test['title'] = test['title'].replace('Ms', 'Miss')\n",
    "test['title'] = test['title'].replace('Mme', 'Mrs')\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "\n",
    "titles_ohe_train = ohe.fit_transform(train[['title']])\n",
    "titles_ohe_test = ohe.transform(test[['title']])\n",
    "\n",
    "train = pd.concat([train.drop(columns=['title']), titles_ohe_train], axis=1)\n",
    "test = pd.concat([test.drop(columns=['title']), titles_ohe_test], axis=1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff190ee-fbb7-4797-bca1-4c71939116a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete the cabin, lets suppose that the family was in same cabin.\n",
    "    \n",
    "nan_cabin_passenger = train.loc[train['Cabin'].isnull() \n",
    "                                & train['travel_with_family'] == 1][\n",
    "                                ['Surname', 'travel_with_family', 'Name', 'Cabin']\n",
    "                                ]\n",
    "cabin_family = train.loc[~train['Cabin'].isnull() & train['Surname'].isin(nan_cabin_passenger['Surname'])][['Name', 'Surname', 'Cabin']]\n",
    "mapping_surname_cabin = cabin_family.drop_duplicates('Surname')\n",
    "mapping_surname_cabin = mapping_surname_cabin.set_index('Surname')['Cabin']\n",
    "train['Cabin'] = train['Cabin'].fillna(train['Surname'].map(mapping_surname_cabin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea005853-9c68-4bad-afdd-bd1b49ae885d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Cabin'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Jupyter/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Cabin'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(val) // \u001b[38;5;28mlen\u001b[39m(val)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m cabins_letter = \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCabin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m).str.replace(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[^a-zA-Z]\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, regex=\u001b[38;5;28;01mTrue\u001b[39;00m).str.split()\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchoose_random\u001b[39m(val):\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m val \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m val:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Jupyter/venv/lib/python3.13/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Jupyter/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Cabin'"
     ]
    }
   ],
   "source": [
    "# Dealing with miss values about cabin and encoding the cabin\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "def get_num_cabin(x):\n",
    "    if not x:\n",
    "        return 0\n",
    "    val = []\n",
    "    try:\n",
    "        for v in x:\n",
    "            val.append(int(v))\n",
    "    except:\n",
    "        return 0\n",
    "    return sum(val) // len(val)\n",
    " \n",
    "cabins_letter = train['Cabin'].astype(str).str.replace(r'[^a-zA-Z]', '', regex=True).str.split()\n",
    "def choose_random(val):\n",
    "    if 'nan' in val or '' in val:\n",
    "        return 'U'\n",
    "    \n",
    "    if len(val) > 1:\n",
    "        choice = np.random.choice(val)\n",
    "        if len(choice) > 1:\n",
    "            return choice[0]\n",
    "            \n",
    "        return choice\n",
    "    if len(val[0]) > 1:\n",
    "        return val[0][0]\n",
    "        \n",
    "    return val[0]\n",
    "\n",
    "cabins_number = train['Cabin'].str.findall(r'\\d+')\n",
    "train['Cabin_Number'] = cabins_number.apply(get_num_cabin)\n",
    "cabins_number = test['Cabin'].str.findall(r'\\d+')\n",
    "test['Cabin_Number'] = cabins_number.apply(get_num_cabin)\n",
    "\n",
    "cabins_letter = cabins_letter.apply(choose_random)\n",
    "train['Cabin'] = cabins_letter\n",
    "cabins_letter_test = test['Cabin'].astype(str).str.replace(r'[^a-zA-Z]', '', regex=True).str.split()\n",
    "cabins_letter_test = cabins_letter_test.apply(choose_random)\n",
    "test['Cabin'] = cabins_letter_test\n",
    "\n",
    "# enc = OrdinalEncoder()\n",
    "# cabin_enc = enc.fit_transform(train[['Cabin']])\n",
    "# train['Cabin'] = cabin_enc[:, 0]\n",
    "\n",
    "# cabin_enc_test = enc.transform(test[['Cabin']])\n",
    "# test['Cabin'] = cabin_enc_test[:, 0]\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# train['Cabin'] = le.fit_transform(train['Cabin'])\n",
    "# test['Cabin'] = le.transform(test['Cabin'])\n",
    "\n",
    "ohe_cab = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "\n",
    "cabin_ohe_train = ohe_cab.fit_transform(train[['Cabin']])\n",
    "cabin_ohe_test = ohe_cab.transform(test[['Cabin']])\n",
    "\n",
    "train = pd.concat([train.drop(columns=['Cabin']), cabin_ohe_train], axis=1)\n",
    "test = pd.concat([test.drop(columns=['Cabin']), cabin_ohe_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080e343a-f6f7-4ce5-8079-57cafc1e057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with the missing values about embarked.\n",
    "# I will put the mathematical mode.\n",
    "\n",
    "mode_train = train['Embarked'].value_counts()\n",
    "train['Embarked'] = train['Embarked'].fillna('S')\n",
    "\n",
    "# Encoding \"Embarked\" \n",
    "map_embarked = {'S': 0, 'C': 1, 'Q': 2}\n",
    "train['Embarked'] = train['Embarked'].map(map_embarked)\n",
    "test['Embarked'] = test['Embarked'].map(map_embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe88ff3-99ec-4ef1-8007-b49fbde682c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134922/4184202167.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['Sex'] = train['Sex'].replace(to_replace=['male', 'female'], value=[0, 1])\n",
      "/tmp/ipykernel_134922/4184202167.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['Sex'] = test['Sex'].replace(to_replace=['male', 'female'], value=[0, 1])\n"
     ]
    }
   ],
   "source": [
    "train['Sex'] = train['Sex'].replace(to_replace=['male', 'female'], value=[0, 1])\n",
    "test['Sex'] = test['Sex'].replace(to_replace=['male', 'female'], value=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5fd6503-0d58-4c3f-b581-a858eb723bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 'ticket' column contains string data. The authors suggest using an encoding method for this data type. I am applying the Feature Hashing method,\n",
    "#as described in Feature Engineering and Selection by Max Kuhn and Kjell Johnson\n",
    "\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "features = 2**2\n",
    "# features = 3\n",
    "\n",
    "h = FeatureHasher(n_features=features, input_type='string')\n",
    "ticket_proc = train['Ticket'].astype(str).str.replace('/', ' ', regex=False).str.replace(r'[^\\w\\s]', '', regex=True).str.split()\n",
    "ticket_feat_hasher = h.fit_transform(ticket_proc).toarray()\n",
    "ticket_feat_hasher_df = pd.DataFrame(ticket_feat_hasher, columns = [f'f{i}' for i in range(len(ticket_feat_hasher[0]))], index = train.index)\n",
    "train = pd.concat([train, ticket_feat_hasher_df], axis=1)\n",
    "train = train.drop(columns = ['Ticket'])\n",
    "\n",
    "\n",
    "ticket_proc = test['Ticket'].astype(str).str.replace('/', ' ', regex=False).str.replace(r'[^\\w\\s]', '', regex=True).str.split()\n",
    "ticket_feat_hasher = h.transform(ticket_proc).toarray()\n",
    "ticket_feat_hasher_df = pd.DataFrame(ticket_feat_hasher, columns = [f'f{i}' for i in range(len(ticket_feat_hasher[0]))], index = test.index)\n",
    "test = pd.concat([test, ticket_feat_hasher_df], axis=1)\n",
    "test = test.drop(columns = ['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c42f11-8621-44bd-bb38-3ebf94b1a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'].isna().sum() / train['Age'].isna().count() # 20% unknow, 80% know. Remove the unknow data is not appropriate\n",
    "\n",
    "# Solution: Impute data with KNN. Source: Feature Engineering and Selection by Max Kuhn and Kjell Johnson\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "df_aux = train.select_dtypes(include = ['number'])\n",
    "\n",
    "corr = df_aux.corr()['Age']\n",
    "corr_abs = 0.15\n",
    "corr_age_feat = corr[abs(corr) > corr_abs].index\n",
    "# corr[abs(corr) > corr_abs], corr_age_feat\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "data_to_impute = train[corr_age_feat]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_to_impute)\n",
    "\n",
    "imputer_df_pred = imputer.fit_transform(data_scaled) # KNN\n",
    "imputed_data_final = scaler.inverse_transform(imputer_df_pred) # Return to normal scale\n",
    "\n",
    "df_aux_train = pd.DataFrame(imputed_data_final, columns = corr_age_feat, index=train.index)\n",
    "\n",
    "train['Age'] = df_aux_train['Age']\n",
    "\n",
    "\n",
    "data_to_impute_test = test[corr_age_feat]\n",
    "data_scaled_test = scaler.transform(data_to_impute_test)\n",
    "imputer_df_pred_test = imputer.transform(data_scaled_test) # KNN\n",
    "imputed_data_final_test = scaler.inverse_transform(imputer_df_pred_test) # Return to normal scale\n",
    "df_aux_test = pd.DataFrame(imputed_data_final_test, columns = corr_age_feat, index=test.index)\n",
    "test['Age'] = df_aux_test['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f691b5-c0f2-41fd-a136-045f58f13e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers\n",
    "Q1 = train['Age'].quantile(0.25)\n",
    "Q3 = train['Age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "train = train.drop(train.loc[train['Age'] >= upper].index)\n",
    "\n",
    "Q1 = train['Fare'].quantile(0.25)\n",
    "Q3 = train['Fare'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "train = train.drop(train.loc[train['Fare'] >= upper].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "982ae639-4132-4769-9ba7-41adaf40e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(x=train['Fare'])\n",
    "# train['Fare'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7589943a-2afb-4d92-b6c4-e20d63b552c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=['Name', 'Surname'])\n",
    "train = train.drop(columns=['Name', 'Surname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da32dcee-bb47-49fc-aea7-08973c4e2d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>size_family</th>\n",
       "      <th>travel_with_family</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Cabin_U</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240505</td>\n",
       "      <td>0.500950</td>\n",
       "      <td>-0.174272</td>\n",
       "      <td>-0.003642</td>\n",
       "      <td>0.098420</td>\n",
       "      <td>0.237248</td>\n",
       "      <td>0.085753</td>\n",
       "      <td>-0.037396</td>\n",
       "      <td>0.072365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124097</td>\n",
       "      <td>0.131946</td>\n",
       "      <td>0.087008</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>-0.025855</td>\n",
       "      <td>-0.207691</td>\n",
       "      <td>0.025416</td>\n",
       "      <td>-0.025276</td>\n",
       "      <td>-0.062979</td>\n",
       "      <td>0.109256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.240505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016664</td>\n",
       "      <td>-0.268402</td>\n",
       "      <td>0.111562</td>\n",
       "      <td>0.081156</td>\n",
       "      <td>-0.585399</td>\n",
       "      <td>0.139745</td>\n",
       "      <td>0.154740</td>\n",
       "      <td>0.087423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265017</td>\n",
       "      <td>-0.235577</td>\n",
       "      <td>-0.010532</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>-0.073339</td>\n",
       "      <td>0.603630</td>\n",
       "      <td>0.044150</td>\n",
       "      <td>0.059987</td>\n",
       "      <td>0.063986</td>\n",
       "      <td>-0.088671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.500950</td>\n",
       "      <td>-0.016664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.208441</td>\n",
       "      <td>0.144585</td>\n",
       "      <td>0.288597</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.113859</td>\n",
       "      <td>0.148392</td>\n",
       "      <td>0.187453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.032777</td>\n",
       "      <td>0.106131</td>\n",
       "      <td>-0.024521</td>\n",
       "      <td>-0.026302</td>\n",
       "      <td>-0.100017</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>-0.046572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.174272</td>\n",
       "      <td>-0.268402</td>\n",
       "      <td>-0.208441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.398489</td>\n",
       "      <td>-0.257612</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>-0.008580</td>\n",
       "      <td>-0.303065</td>\n",
       "      <td>-0.326155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050286</td>\n",
       "      <td>0.100342</td>\n",
       "      <td>-0.085632</td>\n",
       "      <td>-0.079354</td>\n",
       "      <td>0.036709</td>\n",
       "      <td>-0.195855</td>\n",
       "      <td>0.041715</td>\n",
       "      <td>-0.027780</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.048074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.003642</td>\n",
       "      <td>0.111562</td>\n",
       "      <td>0.144585</td>\n",
       "      <td>-0.398489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409539</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>-0.042389</td>\n",
       "      <td>0.648547</td>\n",
       "      <td>0.493414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034355</td>\n",
       "      <td>-0.055912</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>-0.017586</td>\n",
       "      <td>0.086622</td>\n",
       "      <td>-0.124002</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>-0.086954</td>\n",
       "      <td>-0.047723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.098420</td>\n",
       "      <td>0.081156</td>\n",
       "      <td>0.288597</td>\n",
       "      <td>-0.257612</td>\n",
       "      <td>0.409539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>-0.056970</td>\n",
       "      <td>0.593373</td>\n",
       "      <td>0.456315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>-0.055490</td>\n",
       "      <td>0.051913</td>\n",
       "      <td>0.083275</td>\n",
       "      <td>-0.015678</td>\n",
       "      <td>0.047636</td>\n",
       "      <td>-0.158113</td>\n",
       "      <td>0.029182</td>\n",
       "      <td>0.013558</td>\n",
       "      <td>-0.057652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.237248</td>\n",
       "      <td>-0.585399</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.340954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085797</td>\n",
       "      <td>0.250083</td>\n",
       "      <td>0.269386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201053</td>\n",
       "      <td>0.180321</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>-0.022283</td>\n",
       "      <td>0.047257</td>\n",
       "      <td>-0.430327</td>\n",
       "      <td>-0.057415</td>\n",
       "      <td>-0.013402</td>\n",
       "      <td>-0.104626</td>\n",
       "      <td>0.038829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.085753</td>\n",
       "      <td>0.139745</td>\n",
       "      <td>0.113859</td>\n",
       "      <td>-0.008580</td>\n",
       "      <td>-0.042389</td>\n",
       "      <td>-0.056970</td>\n",
       "      <td>-0.085797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033754</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048467</td>\n",
       "      <td>0.014117</td>\n",
       "      <td>-0.011902</td>\n",
       "      <td>-0.038168</td>\n",
       "      <td>-0.019047</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>-0.081539</td>\n",
       "      <td>-0.004833</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>-0.038502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_family</th>\n",
       "      <td>-0.037396</td>\n",
       "      <td>0.154740</td>\n",
       "      <td>0.148392</td>\n",
       "      <td>-0.303065</td>\n",
       "      <td>0.648547</td>\n",
       "      <td>0.593373</td>\n",
       "      <td>0.250083</td>\n",
       "      <td>-0.033754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728679</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046932</td>\n",
       "      <td>-0.033291</td>\n",
       "      <td>0.010604</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>-0.020334</td>\n",
       "      <td>0.021194</td>\n",
       "      <td>-0.125827</td>\n",
       "      <td>0.017142</td>\n",
       "      <td>-0.077877</td>\n",
       "      <td>-0.086507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel_with_family</th>\n",
       "      <td>0.072365</td>\n",
       "      <td>0.087423</td>\n",
       "      <td>0.187453</td>\n",
       "      <td>-0.326155</td>\n",
       "      <td>0.493414</td>\n",
       "      <td>0.456315</td>\n",
       "      <td>0.269386</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.728679</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058940</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.055228</td>\n",
       "      <td>0.093262</td>\n",
       "      <td>-0.027905</td>\n",
       "      <td>-0.063469</td>\n",
       "      <td>-0.168180</td>\n",
       "      <td>-0.011812</td>\n",
       "      <td>-0.023740</td>\n",
       "      <td>0.009902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_Master</th>\n",
       "      <td>0.100804</td>\n",
       "      <td>0.080342</td>\n",
       "      <td>-0.150590</td>\n",
       "      <td>-0.402899</td>\n",
       "      <td>0.451474</td>\n",
       "      <td>0.270827</td>\n",
       "      <td>0.148085</td>\n",
       "      <td>0.006388</td>\n",
       "      <td>0.317312</td>\n",
       "      <td>0.273114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036116</td>\n",
       "      <td>-0.014003</td>\n",
       "      <td>0.108027</td>\n",
       "      <td>-0.015982</td>\n",
       "      <td>-0.007976</td>\n",
       "      <td>0.034650</td>\n",
       "      <td>-0.070789</td>\n",
       "      <td>0.042960</td>\n",
       "      <td>-0.010312</td>\n",
       "      <td>0.042204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_Miss</th>\n",
       "      <td>0.313427</td>\n",
       "      <td>0.080337</td>\n",
       "      <td>0.707306</td>\n",
       "      <td>-0.364490</td>\n",
       "      <td>0.089313</td>\n",
       "      <td>0.102689</td>\n",
       "      <td>-0.017363</td>\n",
       "      <td>0.191356</td>\n",
       "      <td>0.091148</td>\n",
       "      <td>0.052443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015898</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>0.009124</td>\n",
       "      <td>0.057647</td>\n",
       "      <td>-0.017344</td>\n",
       "      <td>0.040981</td>\n",
       "      <td>-0.055462</td>\n",
       "      <td>0.048432</td>\n",
       "      <td>-0.038587</td>\n",
       "      <td>-0.065808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_Mr</th>\n",
       "      <td>-0.512474</td>\n",
       "      <td>0.044083</td>\n",
       "      <td>-0.859608</td>\n",
       "      <td>0.329784</td>\n",
       "      <td>-0.317721</td>\n",
       "      <td>-0.376908</td>\n",
       "      <td>-0.217328</td>\n",
       "      <td>-0.116438</td>\n",
       "      <td>-0.270414</td>\n",
       "      <td>-0.278992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038492</td>\n",
       "      <td>0.012775</td>\n",
       "      <td>-0.071998</td>\n",
       "      <td>-0.091231</td>\n",
       "      <td>0.028526</td>\n",
       "      <td>0.039295</td>\n",
       "      <td>0.125569</td>\n",
       "      <td>-0.020694</td>\n",
       "      <td>0.065293</td>\n",
       "      <td>0.027486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_Mrs</th>\n",
       "      <td>0.322339</td>\n",
       "      <td>-0.102113</td>\n",
       "      <td>0.557528</td>\n",
       "      <td>0.127269</td>\n",
       "      <td>0.097012</td>\n",
       "      <td>0.287144</td>\n",
       "      <td>0.205740</td>\n",
       "      <td>-0.067696</td>\n",
       "      <td>0.102421</td>\n",
       "      <td>0.199076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.036281</td>\n",
       "      <td>0.081482</td>\n",
       "      <td>-0.013671</td>\n",
       "      <td>-0.067886</td>\n",
       "      <td>-0.068291</td>\n",
       "      <td>-0.051513</td>\n",
       "      <td>-0.042895</td>\n",
       "      <td>0.012446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_Rare</th>\n",
       "      <td>-0.008064</td>\n",
       "      <td>-0.231767</td>\n",
       "      <td>-0.072183</td>\n",
       "      <td>0.159572</td>\n",
       "      <td>-0.049712</td>\n",
       "      <td>-0.058524</td>\n",
       "      <td>0.084323</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>-0.031827</td>\n",
       "      <td>-0.053953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079320</td>\n",
       "      <td>-0.032534</td>\n",
       "      <td>-0.021616</td>\n",
       "      <td>-0.011479</td>\n",
       "      <td>-0.005728</td>\n",
       "      <td>-0.128573</td>\n",
       "      <td>-0.011946</td>\n",
       "      <td>-0.005386</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>-0.004466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_Number</th>\n",
       "      <td>0.116707</td>\n",
       "      <td>-0.461746</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.183019</td>\n",
       "      <td>-0.074974</td>\n",
       "      <td>-0.070203</td>\n",
       "      <td>0.287164</td>\n",
       "      <td>-0.024475</td>\n",
       "      <td>-0.034179</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126022</td>\n",
       "      <td>0.351706</td>\n",
       "      <td>0.156989</td>\n",
       "      <td>-0.006106</td>\n",
       "      <td>-0.012106</td>\n",
       "      <td>-0.742524</td>\n",
       "      <td>0.017828</td>\n",
       "      <td>-0.048710</td>\n",
       "      <td>-0.073934</td>\n",
       "      <td>0.077449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_A</th>\n",
       "      <td>0.025483</td>\n",
       "      <td>-0.236822</td>\n",
       "      <td>-0.050764</td>\n",
       "      <td>0.125154</td>\n",
       "      <td>-0.044801</td>\n",
       "      <td>-0.059164</td>\n",
       "      <td>0.157942</td>\n",
       "      <td>0.048073</td>\n",
       "      <td>0.024041</td>\n",
       "      <td>0.035162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022193</td>\n",
       "      <td>-0.027834</td>\n",
       "      <td>-0.018494</td>\n",
       "      <td>-0.009821</td>\n",
       "      <td>-0.004901</td>\n",
       "      <td>-0.300587</td>\n",
       "      <td>-0.014631</td>\n",
       "      <td>-0.008894</td>\n",
       "      <td>-0.008893</td>\n",
       "      <td>0.015307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_B</th>\n",
       "      <td>0.025065</td>\n",
       "      <td>-0.263377</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.103506</td>\n",
       "      <td>-0.023112</td>\n",
       "      <td>-0.005276</td>\n",
       "      <td>0.190921</td>\n",
       "      <td>-0.006410</td>\n",
       "      <td>0.054158</td>\n",
       "      <td>0.076498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027968</td>\n",
       "      <td>-0.035078</td>\n",
       "      <td>-0.023307</td>\n",
       "      <td>-0.012377</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>-0.378813</td>\n",
       "      <td>0.069897</td>\n",
       "      <td>0.009319</td>\n",
       "      <td>-0.030539</td>\n",
       "      <td>-0.020155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_C</th>\n",
       "      <td>0.069640</td>\n",
       "      <td>-0.352478</td>\n",
       "      <td>-0.030099</td>\n",
       "      <td>0.156489</td>\n",
       "      <td>-0.040571</td>\n",
       "      <td>-0.070339</td>\n",
       "      <td>0.223791</td>\n",
       "      <td>-0.017636</td>\n",
       "      <td>-0.042518</td>\n",
       "      <td>-0.035864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029874</td>\n",
       "      <td>-0.037468</td>\n",
       "      <td>-0.024895</td>\n",
       "      <td>-0.013220</td>\n",
       "      <td>-0.006597</td>\n",
       "      <td>-0.404627</td>\n",
       "      <td>-0.022403</td>\n",
       "      <td>-0.063720</td>\n",
       "      <td>-0.067310</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_D</th>\n",
       "      <td>0.124097</td>\n",
       "      <td>-0.265017</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>0.050286</td>\n",
       "      <td>-0.034355</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.201053</td>\n",
       "      <td>-0.048467</td>\n",
       "      <td>-0.046932</td>\n",
       "      <td>-0.058940</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033401</td>\n",
       "      <td>-0.022193</td>\n",
       "      <td>-0.011785</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>-0.360703</td>\n",
       "      <td>-0.011523</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>-0.041964</td>\n",
       "      <td>-0.004585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_E</th>\n",
       "      <td>0.131946</td>\n",
       "      <td>-0.235577</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.100342</td>\n",
       "      <td>-0.055912</td>\n",
       "      <td>-0.055490</td>\n",
       "      <td>0.180321</td>\n",
       "      <td>0.014117</td>\n",
       "      <td>-0.033291</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027834</td>\n",
       "      <td>-0.014781</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-0.452397</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.059255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_F</th>\n",
       "      <td>0.087008</td>\n",
       "      <td>-0.010532</td>\n",
       "      <td>0.032777</td>\n",
       "      <td>-0.085632</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>0.051913</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>-0.011902</td>\n",
       "      <td>0.010604</td>\n",
       "      <td>0.055228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022193</td>\n",
       "      <td>-0.027834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009821</td>\n",
       "      <td>-0.004901</td>\n",
       "      <td>-0.300587</td>\n",
       "      <td>-0.014631</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.091817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_G</th>\n",
       "      <td>0.024422</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>0.106131</td>\n",
       "      <td>-0.079354</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.083275</td>\n",
       "      <td>-0.022283</td>\n",
       "      <td>-0.038168</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.093262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011785</td>\n",
       "      <td>-0.014781</td>\n",
       "      <td>-0.009821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002602</td>\n",
       "      <td>-0.159620</td>\n",
       "      <td>-0.061175</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.044151</td>\n",
       "      <td>0.069072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_T</th>\n",
       "      <td>-0.025855</td>\n",
       "      <td>-0.073339</td>\n",
       "      <td>-0.024521</td>\n",
       "      <td>0.036709</td>\n",
       "      <td>-0.017586</td>\n",
       "      <td>-0.015678</td>\n",
       "      <td>0.047257</td>\n",
       "      <td>-0.019047</td>\n",
       "      <td>-0.020334</td>\n",
       "      <td>-0.027905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-0.004901</td>\n",
       "      <td>-0.002602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.079654</td>\n",
       "      <td>-0.061620</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>-0.006422</td>\n",
       "      <td>-0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_U</th>\n",
       "      <td>-0.207691</td>\n",
       "      <td>0.603630</td>\n",
       "      <td>-0.026302</td>\n",
       "      <td>-0.195855</td>\n",
       "      <td>0.086622</td>\n",
       "      <td>0.047636</td>\n",
       "      <td>-0.430327</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.021194</td>\n",
       "      <td>-0.063469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360703</td>\n",
       "      <td>-0.452397</td>\n",
       "      <td>-0.300587</td>\n",
       "      <td>-0.159620</td>\n",
       "      <td>-0.079654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007088</td>\n",
       "      <td>0.015939</td>\n",
       "      <td>0.053349</td>\n",
       "      <td>-0.096099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0</th>\n",
       "      <td>0.025416</td>\n",
       "      <td>0.044150</td>\n",
       "      <td>-0.100017</td>\n",
       "      <td>0.041715</td>\n",
       "      <td>-0.124002</td>\n",
       "      <td>-0.158113</td>\n",
       "      <td>-0.057415</td>\n",
       "      <td>-0.081539</td>\n",
       "      <td>-0.125827</td>\n",
       "      <td>-0.168180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011523</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>-0.014631</td>\n",
       "      <td>-0.061175</td>\n",
       "      <td>-0.061620</td>\n",
       "      <td>-0.007088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055443</td>\n",
       "      <td>0.084079</td>\n",
       "      <td>0.048918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>-0.025276</td>\n",
       "      <td>0.059987</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>-0.027780</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.029182</td>\n",
       "      <td>-0.013402</td>\n",
       "      <td>-0.004833</td>\n",
       "      <td>0.017142</td>\n",
       "      <td>-0.011812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.015939</td>\n",
       "      <td>0.055443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>-0.007038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>-0.062979</td>\n",
       "      <td>0.063986</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>-0.086954</td>\n",
       "      <td>0.013558</td>\n",
       "      <td>-0.104626</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>-0.077877</td>\n",
       "      <td>-0.023740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041964</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.044151</td>\n",
       "      <td>-0.006422</td>\n",
       "      <td>0.053349</td>\n",
       "      <td>0.084079</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>0.109256</td>\n",
       "      <td>-0.088671</td>\n",
       "      <td>-0.046572</td>\n",
       "      <td>0.048074</td>\n",
       "      <td>-0.047723</td>\n",
       "      <td>-0.057652</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>-0.038502</td>\n",
       "      <td>-0.086507</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004585</td>\n",
       "      <td>0.059255</td>\n",
       "      <td>0.091817</td>\n",
       "      <td>0.069072</td>\n",
       "      <td>-0.001012</td>\n",
       "      <td>-0.096099</td>\n",
       "      <td>0.048918</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>0.095821</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Survived    Pclass       Sex       Age     SibSp  \\\n",
       "Survived            1.000000 -0.240505  0.500950 -0.174272 -0.003642   \n",
       "Pclass             -0.240505  1.000000 -0.016664 -0.268402  0.111562   \n",
       "Sex                 0.500950 -0.016664  1.000000 -0.208441  0.144585   \n",
       "Age                -0.174272 -0.268402 -0.208441  1.000000 -0.398489   \n",
       "SibSp              -0.003642  0.111562  0.144585 -0.398489  1.000000   \n",
       "Parch               0.098420  0.081156  0.288597 -0.257612  0.409539   \n",
       "Fare                0.237248 -0.585399  0.138300  0.002597  0.375000   \n",
       "Embarked            0.085753  0.139745  0.113859 -0.008580 -0.042389   \n",
       "size_family        -0.037396  0.154740  0.148392 -0.303065  0.648547   \n",
       "travel_with_family  0.072365  0.087423  0.187453 -0.326155  0.493414   \n",
       "title_Master        0.100804  0.080342 -0.150590 -0.402899  0.451474   \n",
       "title_Miss          0.313427  0.080337  0.707306 -0.364490  0.089313   \n",
       "title_Mr           -0.512474  0.044083 -0.859608  0.329784 -0.317721   \n",
       "title_Mrs           0.322339 -0.102113  0.557528  0.127269  0.097012   \n",
       "title_Rare         -0.008064 -0.231767 -0.072183  0.159572 -0.049712   \n",
       "Cabin_Number        0.116707 -0.461746  0.002170  0.183019 -0.074974   \n",
       "Cabin_A             0.025483 -0.236822 -0.050764  0.125154 -0.044801   \n",
       "Cabin_B             0.025065 -0.263377  0.017380  0.103506 -0.023112   \n",
       "Cabin_C             0.069640 -0.352478 -0.030099  0.156489 -0.040571   \n",
       "Cabin_D             0.124097 -0.265017  0.046851  0.050286 -0.034355   \n",
       "Cabin_E             0.131946 -0.235577  0.002688  0.100342 -0.055912   \n",
       "Cabin_F             0.087008 -0.010532  0.032777 -0.085632  0.009103   \n",
       "Cabin_G             0.024422  0.050956  0.106131 -0.079354  0.004834   \n",
       "Cabin_T            -0.025855 -0.073339 -0.024521  0.036709 -0.017586   \n",
       "Cabin_U            -0.207691  0.603630 -0.026302 -0.195855  0.086622   \n",
       "f0                  0.025416  0.044150 -0.100017  0.041715 -0.124002   \n",
       "f1                 -0.025276  0.059987  0.008940 -0.027780  0.067568   \n",
       "f2                 -0.062979  0.063986 -0.064000  0.020482 -0.086954   \n",
       "f3                  0.109256 -0.088671 -0.046572  0.048074 -0.047723   \n",
       "\n",
       "                       Parch      Fare  Embarked  size_family  \\\n",
       "Survived            0.098420  0.237248  0.085753    -0.037396   \n",
       "Pclass              0.081156 -0.585399  0.139745     0.154740   \n",
       "Sex                 0.288597  0.138300  0.113859     0.148392   \n",
       "Age                -0.257612  0.002597 -0.008580    -0.303065   \n",
       "SibSp               0.409539  0.375000 -0.042389     0.648547   \n",
       "Parch               1.000000  0.340954 -0.056970     0.593373   \n",
       "Fare                0.340954  1.000000 -0.085797     0.250083   \n",
       "Embarked           -0.056970 -0.085797  1.000000    -0.033754   \n",
       "size_family         0.593373  0.250083 -0.033754     1.000000   \n",
       "travel_with_family  0.456315  0.269386  0.000177     0.728679   \n",
       "title_Master        0.270827  0.148085  0.006388     0.317312   \n",
       "title_Miss          0.102689 -0.017363  0.191356     0.091148   \n",
       "title_Mr           -0.376908 -0.217328 -0.116438    -0.270414   \n",
       "title_Mrs           0.287144  0.205740 -0.067696     0.102421   \n",
       "title_Rare         -0.058524  0.084323  0.019294    -0.031827   \n",
       "Cabin_Number       -0.070203  0.287164 -0.024475    -0.034179   \n",
       "Cabin_A            -0.059164  0.157942  0.048073     0.024041   \n",
       "Cabin_B            -0.005276  0.190921 -0.006410     0.054158   \n",
       "Cabin_C            -0.070339  0.223791 -0.017636    -0.042518   \n",
       "Cabin_D             0.011940  0.201053 -0.048467    -0.046932   \n",
       "Cabin_E            -0.055490  0.180321  0.014117    -0.033291   \n",
       "Cabin_F             0.051913  0.012080 -0.011902     0.010604   \n",
       "Cabin_G             0.083275 -0.022283 -0.038168     0.009199   \n",
       "Cabin_T            -0.015678  0.047257 -0.019047    -0.020334   \n",
       "Cabin_U             0.047636 -0.430327  0.020556     0.021194   \n",
       "f0                 -0.158113 -0.057415 -0.081539    -0.125827   \n",
       "f1                  0.029182 -0.013402 -0.004833     0.017142   \n",
       "f2                  0.013558 -0.104626 -0.116309    -0.077877   \n",
       "f3                 -0.057652  0.038829 -0.038502    -0.086507   \n",
       "\n",
       "                    travel_with_family  ...   Cabin_D   Cabin_E   Cabin_F  \\\n",
       "Survived                      0.072365  ...  0.124097  0.131946  0.087008   \n",
       "Pclass                        0.087423  ... -0.265017 -0.235577 -0.010532   \n",
       "Sex                           0.187453  ...  0.046851  0.002688  0.032777   \n",
       "Age                          -0.326155  ...  0.050286  0.100342 -0.085632   \n",
       "SibSp                         0.493414  ... -0.034355 -0.055912  0.009103   \n",
       "Parch                         0.456315  ...  0.011940 -0.055490  0.051913   \n",
       "Fare                          0.269386  ...  0.201053  0.180321  0.012080   \n",
       "Embarked                      0.000177  ... -0.048467  0.014117 -0.011902   \n",
       "size_family                   0.728679  ... -0.046932 -0.033291  0.010604   \n",
       "travel_with_family            1.000000  ... -0.058940  0.046100  0.055228   \n",
       "title_Master                  0.273114  ... -0.036116 -0.014003  0.108027   \n",
       "title_Miss                    0.052443  ... -0.015898 -0.014025  0.009124   \n",
       "title_Mr                     -0.278992  ... -0.038492  0.012775 -0.071998   \n",
       "title_Mrs                     0.199076  ...  0.061111  0.021897  0.036281   \n",
       "title_Rare                   -0.053953  ...  0.079320 -0.032534 -0.021616   \n",
       "Cabin_Number                  0.021413  ...  0.126022  0.351706  0.156989   \n",
       "Cabin_A                       0.035162  ... -0.022193 -0.027834 -0.018494   \n",
       "Cabin_B                       0.076498  ... -0.027968 -0.035078 -0.023307   \n",
       "Cabin_C                      -0.035864  ... -0.029874 -0.037468 -0.024895   \n",
       "Cabin_D                      -0.058940  ...  1.000000 -0.033401 -0.022193   \n",
       "Cabin_E                       0.046100  ... -0.033401  1.000000 -0.027834   \n",
       "Cabin_F                       0.055228  ... -0.022193 -0.027834  1.000000   \n",
       "Cabin_G                       0.093262  ... -0.011785 -0.014781 -0.009821   \n",
       "Cabin_T                      -0.027905  ... -0.005881 -0.007376 -0.004901   \n",
       "Cabin_U                      -0.063469  ... -0.360703 -0.452397 -0.300587   \n",
       "f0                           -0.168180  ... -0.011523  0.037385 -0.014631   \n",
       "f1                           -0.011812  ...  0.022556  0.000057  0.007394   \n",
       "f2                           -0.023740  ... -0.041964  0.005233  0.006446   \n",
       "f3                            0.009902  ... -0.004585  0.059255  0.091817   \n",
       "\n",
       "                     Cabin_G   Cabin_T   Cabin_U        f0        f1  \\\n",
       "Survived            0.024422 -0.025855 -0.207691  0.025416 -0.025276   \n",
       "Pclass              0.050956 -0.073339  0.603630  0.044150  0.059987   \n",
       "Sex                 0.106131 -0.024521 -0.026302 -0.100017  0.008940   \n",
       "Age                -0.079354  0.036709 -0.195855  0.041715 -0.027780   \n",
       "SibSp               0.004834 -0.017586  0.086622 -0.124002  0.067568   \n",
       "Parch               0.083275 -0.015678  0.047636 -0.158113  0.029182   \n",
       "Fare               -0.022283  0.047257 -0.430327 -0.057415 -0.013402   \n",
       "Embarked           -0.038168 -0.019047  0.020556 -0.081539 -0.004833   \n",
       "size_family         0.009199 -0.020334  0.021194 -0.125827  0.017142   \n",
       "travel_with_family  0.093262 -0.027905 -0.063469 -0.168180 -0.011812   \n",
       "title_Master       -0.015982 -0.007976  0.034650 -0.070789  0.042960   \n",
       "title_Miss          0.057647 -0.017344  0.040981 -0.055462  0.048432   \n",
       "title_Mr           -0.091231  0.028526  0.039295  0.125569 -0.020694   \n",
       "title_Mrs           0.081482 -0.013671 -0.067886 -0.068291 -0.051513   \n",
       "title_Rare         -0.011479 -0.005728 -0.128573 -0.011946 -0.005386   \n",
       "Cabin_Number       -0.006106 -0.012106 -0.742524  0.017828 -0.048710   \n",
       "Cabin_A            -0.009821 -0.004901 -0.300587 -0.014631 -0.008894   \n",
       "Cabin_B            -0.012377 -0.006176 -0.378813  0.069897  0.009319   \n",
       "Cabin_C            -0.013220 -0.006597 -0.404627 -0.022403 -0.063720   \n",
       "Cabin_D            -0.011785 -0.005881 -0.360703 -0.011523  0.022556   \n",
       "Cabin_E            -0.014781 -0.007376 -0.452397  0.037385  0.000057   \n",
       "Cabin_F            -0.009821 -0.004901 -0.300587 -0.014631  0.007394   \n",
       "Cabin_G             1.000000 -0.002602 -0.159620 -0.061175  0.003927   \n",
       "Cabin_T            -0.002602  1.000000 -0.079654 -0.061620  0.001959   \n",
       "Cabin_U            -0.159620 -0.079654  1.000000 -0.007088  0.015939   \n",
       "f0                 -0.061175 -0.061620 -0.007088  1.000000  0.055443   \n",
       "f1                  0.003927  0.001959  0.015939  0.055443  1.000000   \n",
       "f2                  0.044151 -0.006422  0.053349  0.084079  0.006254   \n",
       "f3                  0.069072 -0.001012 -0.096099  0.048918 -0.007038   \n",
       "\n",
       "                          f2        f3  \n",
       "Survived           -0.062979  0.109256  \n",
       "Pclass              0.063986 -0.088671  \n",
       "Sex                -0.064000 -0.046572  \n",
       "Age                 0.020482  0.048074  \n",
       "SibSp              -0.086954 -0.047723  \n",
       "Parch               0.013558 -0.057652  \n",
       "Fare               -0.104626  0.038829  \n",
       "Embarked           -0.116309 -0.038502  \n",
       "size_family        -0.077877 -0.086507  \n",
       "travel_with_family -0.023740  0.009902  \n",
       "title_Master       -0.010312  0.042204  \n",
       "title_Miss         -0.038587 -0.065808  \n",
       "title_Mr            0.065293  0.027486  \n",
       "title_Mrs          -0.042895  0.012446  \n",
       "title_Rare         -0.001902 -0.004466  \n",
       "Cabin_Number       -0.073934  0.077449  \n",
       "Cabin_A            -0.008893  0.015307  \n",
       "Cabin_B            -0.030539 -0.020155  \n",
       "Cabin_C            -0.067310  0.052533  \n",
       "Cabin_D            -0.041964 -0.004585  \n",
       "Cabin_E             0.005233  0.059255  \n",
       "Cabin_F             0.006446  0.091817  \n",
       "Cabin_G             0.044151  0.069072  \n",
       "Cabin_T            -0.006422 -0.001012  \n",
       "Cabin_U             0.053349 -0.096099  \n",
       "f0                  0.084079  0.048918  \n",
       "f1                  0.006254 -0.007038  \n",
       "f2                  1.000000  0.095821  \n",
       "f3                  0.095821  1.000000  \n",
       "\n",
       "[29 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()\n",
    "# train\n",
    "# train['Cabin_Number'].value_counts()\n",
    "\n",
    "# 3 2 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d91dc08-6d08-460e-b2e4-7e42535011a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1018, 28), (1018,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=500)\n",
    "abc = AdaBoostClassifier(n_estimators = 5)\n",
    "gbc = GradientBoostingClassifier(n_estimators = 10)\n",
    "\n",
    "y = train['Survived']\n",
    "train = train.drop(columns=['Survived'])\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X, y_res = sm.fit_resample(train, y)\n",
    "X.shape, y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39b522fd-5244-4af5-90db-0cd18d5f19d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AcurÃ¡cia mÃ©dia: 0.8567082005215878\n"
     ]
    }
   ],
   "source": [
    "rfc_cvs = cross_val_score(rfc, X, y_res, cv=5)\n",
    "print(f\"AcurÃ¡cia mÃ©dia: {rfc_cvs.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "382c7ca1-c482-4368-80cc-6e3d649811b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AcurÃ¡cia mÃ©dia: 0.7987153482082487\n"
     ]
    }
   ],
   "source": [
    "abc_cvs = cross_val_score(abc, X, y_res, cv=5)\n",
    "print(f\"AcurÃ¡cia mÃ©dia: {abc_cvs.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cecc4b2c-4ce3-4aff-8868-5ced06135fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AcurÃ¡cia mÃ©dia: 0.839983579638752\n"
     ]
    }
   ],
   "source": [
    "gbc_cvs = cross_val_score(gbc, X, y_res, cv=5)\n",
    "print(f\"AcurÃ¡cia mÃ©dia: {gbc_cvs.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25a79e71-f7a3-4845-ad2f-47bf68a1fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=2, shuffle=True, random_state=0)\n",
    "# best_score = 0\n",
    "# save_y_pred = None\n",
    "# save_X = None\n",
    "# save_y = None\n",
    "\n",
    "# for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "#     X_train_fold, X_test_fold = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#     y_train_fold, y_test_fold = y_res.iloc[train_idx], y_res.iloc[test_idx]\n",
    "\n",
    "#     rfc.fit(X_train_fold, y_train_fold)\n",
    "#     pred = rfc.predict(X_test_fold)\n",
    "#     score = rfc.score(X_test_fold, y_test_fold)\n",
    "    \n",
    "#     if score > best_score:\n",
    "#         best_score = score\n",
    "#         save_y_pred = pred\n",
    "#         save_X = X_test_fold\n",
    "#         save_y = y_test_fold\n",
    "# best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7caf1908-862b-4f81-9994-5ad8ed33b7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=loss,-%7B%27log_loss%27%2C%20%27exponential%27%7D%2C%20default%3D%27log_loss%27\">\n",
       "            loss\n",
       "            <span class=\"param-doc-description\">loss: {'log_loss', 'exponential'}, default='log_loss'<br><br>The loss function to be optimized. 'log_loss' refers to binomial and<br>multinomial deviance, the same as used in logistic regression.<br>It is a good choice for classification with probabilistic outputs.<br>For loss 'exponential', gradient boosting recovers the AdaBoost algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;log_loss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=learning_rate,-float%2C%20default%3D0.1\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: float, default=0.1<br><br>Learning rate shrinks the contribution of each tree by `learning_rate`.<br>There is a trade-off between learning_rate and n_estimators.<br>Values must be in the range `[0.0, inf)`.<br><br>For an example of the effects of this parameter and its interaction with<br>``subsample``, see<br>:ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_regularization.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of boosting stages to perform. Gradient boosting<br>is fairly robust to over-fitting so a large number usually<br>results in better performance.<br>Values must be in the range `[1, inf)`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=subsample,-float%2C%20default%3D1.0\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: float, default=1.0<br><br>The fraction of samples to be used for fitting the individual base<br>learners. If smaller than 1.0 this results in Stochastic Gradient<br>Boosting. `subsample` interacts with the parameter `n_estimators`.<br>Choosing `subsample < 1.0` leads to a reduction of variance<br>and an increase in bias.<br>Values must be in the range `(0.0, 1.0]`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=criterion,-%7B%27friedman_mse%27%2C%20%27squared_error%27%7D%2C%20default%3D%27friedman_mse%27\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {'friedman_mse', 'squared_error'}, default='friedman_mse'<br><br>The function to measure the quality of a split. Supported criteria are<br>'friedman_mse' for the mean squared error with improvement score by<br>Friedman, 'squared_error' for mean squared error. The default value of<br>'friedman_mse' is generally the best as it can provide a better<br>approximation in some cases.<br><br>.. versionadded:: 0.18</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;friedman_mse&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, values must be in the range `[2, inf)`.<br>- If float, values must be in the range `(0.0, 1.0]` and `min_samples_split`<br>  will be `ceil(min_samples_split * n_samples)`.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, values must be in the range `[1, inf)`.<br>- If float, values must be in the range `(0.0, 1.0)` and `min_samples_leaf`<br>  will be `ceil(min_samples_leaf * n_samples)`.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.<br>Values must be in the range `[0.0, 0.5]`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=max_depth,-int%20or%20None%2C%20default%3D3\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int or None, default=3<br><br>Maximum depth of the individual regression estimators. The maximum<br>depth limits the number of nodes in the tree. Tune this parameter<br>for best performance; the best value depends on the interaction<br>of the input variables. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.<br>If int, values must be in the range `[1, inf)`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br>Values must be in the range `[0.0, inf)`.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('init',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=init,-estimator%20or%20%27zero%27%2C%20default%3DNone\">\n",
       "            init\n",
       "            <span class=\"param-doc-description\">init: estimator or 'zero', default=None<br><br>An estimator object that is used to compute the initial predictions.<br>``init`` has to provide :term:`fit` and :term:`predict_proba`. If<br>'zero', the initial raw predictions are set to zero. By default, a<br>``DummyEstimator`` predicting the classes priors is used.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the random seed given to each Tree estimator at each<br>boosting iteration.<br>In addition, it controls the random permutation of the features at<br>each split (see Notes for more details).<br>It also controls the random splitting of the training data to obtain a<br>validation set if `n_iter_no_change` is not None.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=max_features,-%7B%27sqrt%27%2C%20%27log2%27%7D%2C%20int%20or%20float%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {'sqrt', 'log2'}, int or float, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, values must be in the range `[1, inf)`.<br>- If float, values must be in the range `(0.0, 1.0]` and the features<br>  considered at each split will be `max(1, int(max_features * n_features_in_))`.<br>- If 'sqrt', then `max_features=sqrt(n_features)`.<br>- If 'log2', then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>Choosing `max_features < n_features` leads to a reduction of variance<br>and an increase in bias.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Enable verbose output. If 1 then it prints progress and performance<br>once in a while (the more trees the lower the frequency). If greater<br>than 1 then it prints progress and performance for every tree.<br>Values must be in the range `[0, inf)`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>Values must be in the range `[2, inf)`.<br>If `None`, then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just erase the<br>previous solution. See :term:`the Glossary <warm_start>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=validation_fraction,-float%2C%20default%3D0.1\">\n",
       "            validation_fraction\n",
       "            <span class=\"param-doc-description\">validation_fraction: float, default=0.1<br><br>The proportion of training data to set aside as validation set for<br>early stopping. Values must be in the range `(0.0, 1.0)`.<br>Only used if ``n_iter_no_change`` is set to an integer.<br><br>.. versionadded:: 0.20</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=n_iter_no_change,-int%2C%20default%3DNone\">\n",
       "            n_iter_no_change\n",
       "            <span class=\"param-doc-description\">n_iter_no_change: int, default=None<br><br>``n_iter_no_change`` is used to decide if early stopping will be used<br>to terminate training when validation score is not improving. By<br>default it is set to None to disable early stopping. If set to a<br>number, it will set aside ``validation_fraction`` size of the training<br>data as validation and terminate training when validation score is not<br>improving in all of the previous ``n_iter_no_change`` numbers of<br>iterations. The split is stratified.<br>Values must be in the range `[1, inf)`.<br>See<br>:ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_early_stopping.py`.<br><br>.. versionadded:: 0.20</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for the early stopping. When the loss is not improving<br>by at least tol for ``n_iter_no_change`` iterations (if set to a<br>number), the training stops.<br>Values must be in the range `[0.0, inf)`.<br><br>.. versionadded:: 0.20</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed.<br>Values must be in the range `[0.0, inf)`.<br>See :ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a116ce-f30e-4063-bbe9-2824b0348827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Gera a matriz usando o melhor fold salvo\n",
    "# cm = confusion_matrix(save_y, save_y_pred)\n",
    "\n",
    "# # Plota de forma visual\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Morreu', 'Sobreviveu'])\n",
    "# disp.plot(cmap='Blues')\n",
    "# plt.title(f'Matriz de ConfusÃ£o (Melhor Score: {best_score:.4f})')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d67651e1-1aee-4b84-ae2b-274802a5c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbc.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51bf441b-c1ad-4421-88cf-ac10195495e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test.index,\n",
    "    \"Survived\": y_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission6.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Curso de Dados",
   "language": "python",
   "name": "jupyter_notebook_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
