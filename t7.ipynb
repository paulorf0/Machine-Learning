{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7c1bac-b7b5-45cd-aad8-ba6bf1f5fdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  6],\n",
       "       [ 7, 17]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('Dados/Heart_Disease_Prediction.csv')\n",
    "norm = StandardScaler()\n",
    "\n",
    "# df['Heart Disease'] = df['Heart Disease'].map(lambda x: 0 if x == 'Absence' else 1)\n",
    "# corr_matrix = df.corr()['Heart Disease'].sort_values()\n",
    "# corr_matrix\n",
    "\n",
    "y = df['Heart Disease']\n",
    "y = np.where(y == 'Presence', 1, 0)\n",
    "X = df.drop(columns=['Heart Disease'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "X_train = norm.fit_transform(X_train)\n",
    "X_test = norm.fit_transform(X_test)\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "04da9c2b-0c32-46be-84ef-b340de528dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df = pd.read_csv('Dados/music_data/Data/features_3_sec.csv')\n",
    "norm = StandardScaler()\n",
    "pca = PCA(n_components=10)\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "target = 'label'\n",
    "classes = list(set(df[target]))\n",
    "y = le.fit_transform(df[target])\n",
    "\n",
    "X = df.drop(columns = [target])\n",
    "X = X.select_dtypes(include = ['number'])\n",
    "X = norm.fit_transform(X) # Normalização para aplicação do PCA\n",
    "X = pca.fit_transform(X) # Redução de dimensão para 4 atributos apenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b51f2168-be68-4d51-b42a-8d3ba641e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y, \n",
    "    test_size=0.2,       \n",
    "    random_state=42,     \n",
    "    stratify=y          \n",
    ") # Divisão em seleção aleatório em cada subgrupo distinto\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "export_graphviz(dt, out_file='arvore.dot')\n",
    "\n",
    "y = le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fdcb8cfa-f630-4eeb-8d65-898eb195e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      hiphop       0.54      0.56      0.55       200\n",
      "        jazz       0.73      0.76      0.75       199\n",
      "     country       0.46      0.39      0.43       199\n",
      "       blues       0.45      0.53      0.48       200\n",
      "        rock       0.61      0.56      0.59       200\n",
      "      reggae       0.58      0.53      0.55       200\n",
      "         pop       0.76      0.77      0.77       200\n",
      "       metal       0.67      0.59      0.63       200\n",
      "       disco       0.55      0.60      0.57       200\n",
      "   classical       0.47      0.51      0.49       200\n",
      "\n",
      "    accuracy                           0.58      1998\n",
      "   macro avg       0.58      0.58      0.58      1998\n",
      "weighted avg       0.58      0.58      0.58      1998\n",
      "\n",
      "[[112   3  17  14   4  12   8   3  10  17]\n",
      " [  5 152   7   3   1  21   0   2   2   6]\n",
      " [ 31   7  78  13  11  16   2   8  15  18]\n",
      " [  8   2   6 105   9   4  19  11  20  16]\n",
      " [  7   1   7  20 113   0   4  15  26   7]\n",
      " [ 13  30  13   7   1 105   0   8   3  20]\n",
      " [  6   0   2  18   8   1 154   0   2   9]\n",
      " [  1   4   9  17  19   6   0 118  15  11]\n",
      " [ 11   2  15  12  16   4   2   7 121  10]\n",
      " [ 12   7  14  25   4  12  13   5   7 101]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names = classes))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Curso de Dados",
   "language": "python",
   "name": "jupyter_notebook_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
