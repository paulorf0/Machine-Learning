{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7c1bac-b7b5-45cd-aad8-ba6bf1f5fdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  6],\n",
       "       [ 7, 17]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('Dados/Heart_Disease_Prediction.csv')\n",
    "norm = StandardScaler()\n",
    "\n",
    "# df['Heart Disease'] = df['Heart Disease'].map(lambda x: 0 if x == 'Absence' else 1)\n",
    "# corr_matrix = df.corr()['Heart Disease'].sort_values()\n",
    "# corr_matrix\n",
    "\n",
    "y = df['Heart Disease']\n",
    "y = np.where(y == 'Presence', 1, 0)\n",
    "X = df.drop(columns=['Heart Disease'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "X_train = norm.fit_transform(X_train)\n",
    "X_test = norm.fit_transform(X_test)\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "04da9c2b-0c32-46be-84ef-b340de528dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "df = pd.read_csv('Dados/music_data/Data/features_3_sec.csv')\n",
    "norm = StandardScaler()\n",
    "pca = PCA(n_components=4)\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "target = 'label'\n",
    "classes = list(set(df[target]))\n",
    "y = le.fit_transform(df[target])\n",
    "\n",
    "X = df.drop(columns = [target])\n",
    "X = X.select_dtypes(include = ['number'])\n",
    "X = norm.fit_transform(X) # Normalização para aplicação do PCA\n",
    "X = pca.fit_transform(X) # Redução de dimensão para 4 atributos apenas\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y, \n",
    "    test_size=0.2,       \n",
    "    random_state=42,     \n",
    "    stratify=y          \n",
    ") # Divisão em seleção aleatório em cada subgrupo distinto\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "export_graphviz(dt, out_file='arvore.dot')\n",
    "\n",
    "y = le.inverse_transform(y)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "cr_proc = classification_report(y_test, y_pred, target_names = classes)\n",
    "cm_proc = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "X_proc = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cb403739-71b0-4a83-b9db-88c6a81e3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "# Resultados de treinamento sem qualquer tipo de pré-processamento.\n",
    "\n",
    "df = pd.read_csv('Dados/music_data/Data/features_3_sec.csv')\n",
    "# norm = StandardScaler()\n",
    "# pca = PCA(n_components=10)\n",
    "le = LabelEncoder()\n",
    "\n",
    "target = 'label'\n",
    "classes = list(set(df[target]))\n",
    "y = le.fit_transform(df[target])\n",
    "\n",
    "X = df.drop(columns = [target])\n",
    "X = X.select_dtypes(include = ['number'])\n",
    "# X = norm.fit_transform(X) # Normalização para aplicação do PCA\n",
    "# X = pca.fit_transform(X) # Redução de dimensão para 4 atributos apenas\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y, \n",
    "    test_size=0.2,       \n",
    "    random_state=42,     \n",
    "    stratify=y          \n",
    ") # Divisão em seleção aleatório em cada subgrupo distinto\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "# export_graphviz(dt, out_file='arvore.dot')\n",
    "\n",
    "y = le.inverse_transform(y)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "cr_no_proc = classification_report(y_test, y_pred, target_names = classes)\n",
    "cm_no_proc = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "X_no_proc = X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c076f3f5-410b-40d1-a79f-e6b4ebaef432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão Original: (9990, 58), Dimensão Reduzida: (9990, 4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      hiphop       0.63      0.61      0.62       200\n",
      "        jazz       0.82      0.86      0.84       199\n",
      "     country       0.55      0.58      0.57       199\n",
      "       blues       0.56      0.61      0.59       200\n",
      "        rock       0.68      0.63      0.66       200\n",
      "      reggae       0.66      0.64      0.65       200\n",
      "         pop       0.76      0.80      0.78       200\n",
      "       metal       0.78      0.66      0.72       200\n",
      "       disco       0.63      0.61      0.62       200\n",
      "   classical       0.43      0.46      0.44       200\n",
      "\n",
      "    accuracy                           0.65      1998\n",
      "   macro avg       0.65      0.65      0.65      1998\n",
      "weighted avg       0.65      0.65      0.65      1998\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      hiphop       0.38      0.36      0.37       200\n",
      "        jazz       0.71      0.72      0.71       199\n",
      "     country       0.37      0.36      0.36       199\n",
      "       blues       0.26      0.25      0.25       200\n",
      "        rock       0.47      0.48      0.48       200\n",
      "      reggae       0.46      0.43      0.44       200\n",
      "         pop       0.61      0.65      0.62       200\n",
      "       metal       0.62      0.60      0.61       200\n",
      "       disco       0.48      0.47      0.47       200\n",
      "   classical       0.32      0.34      0.33       200\n",
      "\n",
      "    accuracy                           0.47      1998\n",
      "   macro avg       0.47      0.47      0.47      1998\n",
      "weighted avg       0.47      0.47      0.47      1998\n",
      "\n",
      "[[123   2  18   7   5   9   7   1  12  16]\n",
      " [  2 172   6   2   0  14   0   0   0   3]\n",
      " [ 12   9 116  14   1  11   4   4  10  18]\n",
      " [  6   0   6 123  12   5  11   8  11  18]\n",
      " [ 11   0   3  13 126   4   7  13  14   9]\n",
      " [  4  22  18   3   1 127   3   0   9  13]\n",
      " [  8   0   1   6   9   1 160   1   1  13]\n",
      " [  2   0  12  16  13   4   1 132   9  11]\n",
      " [  9   2   8  12  13   6   1   7 123  19]\n",
      " [ 19   2  22  23   4  12  17   3   7  91]] [[ 72   8  25  19  12  15  16   3   8  22]\n",
      " [  7 143   6   2   0  36   0   2   1   2]\n",
      " [ 30   5  71  17   6  13   7  12  18  20]\n",
      " [ 16   2  18  50  32   7  17  20  12  26]\n",
      " [  9   1   9  24  97   1   9   9  27  14]\n",
      " [ 13  40  17   8   1  86   1   8   4  22]\n",
      " [ 15   0   1  17  13   3 129   0   3  19]\n",
      " [  1   0  10  18  16  11   0 121  12  11]\n",
      " [ 12   1  20  15  22   3   6  14  93  14]\n",
      " [ 15   2  15  26   8  14  28   7  16  69]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensão Original: {X.shape}, Dimensão Reduzida: {X_proc.shape}')\n",
    "print(cr_no_proc, cr_proc)\n",
    "print(cm_no_proc, cm_proc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Curso de Dados",
   "language": "python",
   "name": "jupyter_notebook_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
